{
  "name": "Srgan",
  "tagline": "Implementation of [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network arXiv:1609.04802v2]",
  "body": "# SRGAN\r\n\r\nThis is implementation of SRGAN **under working**.\r\n\r\n**Currently only generator part is implemented. SRResNet is implemented but not benchmarked yet.**\r\nSRGAN is hopefully implementation soon.\r\nI can't reproduce PSNR of bicubic in the paper, thus haven't measured the PSNR.\r\n\r\nThe paper is [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802).\r\n\r\nThese images are generated from LR images into 4x SR with trained with with the code. Check [23K results](./demo_results/)\r\n![Reproduce result](demo_results/Set14/img_005_SRF_4_LR.png_SRResnet.png)\r\n![2](demo_results/Set5/img_003_SRF_4_LR.png_SRResnet.png)\r\n![3](demo_results/Set5/img_005_SRF_4_LR.png_SRResnet.png)\r\n\r\nThere more experiments going on. For ex, using preactivation ResNet, 4x4 deconvolution layer to [remove artifacts](http://distill.pub/2016/deconv-checkerboard/).\r\n\t\r\n\r\nThis repository started from altering [Torch7-Network Profiler](https://github.com/e-lab/Torch7-profiling).\r\nUsed ResNet but changed a lot from original. Final using model is `models/resnet-deconv2.lua`.\r\nThe model trained uses 9x9 conv for first and last Conv layers and 15 residual blocks.\r\n\r\nLR Patch is 3x24x24 and SR Patch is 3x96x96. It was vague in the paper that 96x96x is either LR or SR but LR96 was untrainable because of not enough memory (GTX1080).\r\n\r\nTrained with ImageNet (50 images from 1000 classes that have 3 channel and bigger than 3x288x288).\r\nFor first time, just uncomment `prepImageNet` to have paths to images. Save it as `imgBatch.t7`\r\nAfter then, comment these as original code and load it.\r\n\r\n**Only supports, cuda/cudnn backend.**\r\n\r\n### To profile network, \r\n\r\n`th profile-model.lua -m models/resnet-deconv2.lua -r 16x3x24x24 -p cuda`\r\n\r\n### To train network,\r\n\r\nFirst, parse ImageNet dataset. Manually set `datasetPath` variable as your ImageNet path. The path is expected to have 1000 sub category folders.\r\n\r\n`th prepImageNet.lua`\r\n\r\nThen, start train with\r\n\r\n   `th train-SRResNet.lua -model_name 9x9-15res-LR24`\r\n   It will save checkpoints in `model_name` directory.\r\n   \r\n### To resume training, \r\n\r\n   `th train-SRResNet.lua -model_name 9x9-15res-LR24 -checkpoint_start_from models/9x9-15res-LR24/230000.t7`\r\n\r\n### To run/test model,\r\n\r\n\r\n   `th run-SRResNet.lua -checkpoint_path models/9x9-15res-LR24/230000.t7 -dataset BSD100 -result_path results_23K`\r\n\r\n   -dataset can be `BSD100|Set5|Set14.`\r\n   \r\n   If memory is not big enough, will print 'oom' and move on.\r\n\r\n### Model weight\r\n   \r\nFor those who need weight, download this weight in your \r\n\r\n`./checkpoints/9x9-15res-LR24` : [700K iter](https://www.dropbox.com/s/pvq5plly148brpy/700000.t7?dl=0)\r\n`./checkpoints/VGGloss-4x4deconv` : [24K iter](: https://www.dropbox.com/s/ngru09rhfjzfos0/24000.t7?dl=0)\r\n\r\n\r\n# Currently Doing\r\n\r\n1. I've tried training in [preactviation resnet](https://arxiv.org/abs/1603.05027) and [removing artifacts by deconv](http://distill.pub/2016/deconv-checkerboard/). So far, analyzing what are pros and cons.\r\n\r\n2. ContentLoss. Inlcuded `VGG/saveVGG19.sh` to build VGG loss.\r\n\r\n- `luarocks install loadcaffe`\r\n- Download VGG : `cd VGG; ./saveVGG19`\r\n- `luarocks install https://raw.githubusercontent.com/szym/display/master/display-scm-0.rockspec` \r\n\t- Install [display: a browser-based graphics server](https://github.com/szym/display)\r\n- `th -ldisplay.start 8000 0.0.0.0`\r\n- `th train-SRResNet-VGGloss.lua -arch models/resnet-4x4deconv-preact.lua  -model_name VGGloss-4x4deconv -checkpoint_save_iter 1000`\r\n- localhost:8000 shows training visualization\r\n![vis](imgs/vis_training.png)\r\n\r\n3. PSNR\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}